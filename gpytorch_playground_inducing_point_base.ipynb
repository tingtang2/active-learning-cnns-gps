{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170e22cd-a9a9-4536-b4d2-51455e3d702c",
   "metadata": {},
   "source": [
    "## try building a gpytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64663acf-a54e-4fbe-8da9-3677813ae2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch import nn\n",
    "\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.data.data_loader import get_splits, create_dataloaders\n",
    "\n",
    "import math\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a0fc7-93d4-4ca5-8cc7-3ab34a49156a",
   "metadata": {},
   "source": [
    "Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7267cc7f-e06d-496c-966c-041e6fe9f5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X dimensions: (238624, 101, 4) Test X dimensions: (26513, 101, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb5c2df-b9bb-4628-8ea6-bee348affaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "train_dataloader, test_dataloader, num_feats = create_dataloaders(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, device=device, test_batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e482a27-d459-438b-87d2-2a8f60104280",
   "metadata": {},
   "source": [
    "define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e0f585-39d7-4673-9cb8-5574b43d9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self, seq_len: int = 101, \n",
    "                       dropout_prob: float = 0.15,\n",
    "                       MLP_out_dim: int = 50) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # configs\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=self.seq_len, kernel_size=4)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.seq_len, out_channels=self.seq_len//2, kernel_size=4)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dense = nn.Linear(in_features=450, out_features=MLP_out_dim)\n",
    "        self.output = nn.Linear(in_features=MLP_out_dim, out_features=1)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.transpose(1, 2).double()\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = nn.functional.dropout(x, p=self.dropout_prob)        \n",
    "\n",
    "        x = x.reshape((x.size(0), -1))\n",
    "        x = self.dense(x)\n",
    "        #x = nn.functional.relu(x)\n",
    "        #x = nn.functional.dropout(x, p=self.dropout_prob)        \n",
    "\n",
    "        #x = self.output(x)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e76e94fa-66cf-4a28-876b-a2eb1450ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GaussianProcessLayer(gpytorch.models.ApproximateGP):\n",
    "#     def __init__(self, num_dim, grid_bounds=(-10., 10.), grid_size=64):\n",
    "#         variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "#             num_inducing_points=grid_size, batch_shape=torch.Size([num_dim])\n",
    "#         )\n",
    "\n",
    "#         # Our base variational strategy is a GridInterpolationVariationalStrategy,\n",
    "#         # which places variational inducing points on a Grid\n",
    "#         # We wrap it with a IndependentMultitaskVariationalStrategy so that our output is a vector-valued GP\n",
    "#         variational_strategy = gpytorch.variational.IndependentMultitaskVariationalStrategy(\n",
    "#             gpytorch.variational.GridInterpolationVariationalStrategy(\n",
    "#                 self, grid_size=grid_size, grid_bounds=[grid_bounds],\n",
    "#                 variational_distribution=variational_distribution,\n",
    "#             ), num_tasks=num_dim,\n",
    "#         )\n",
    "#         super().__init__(variational_strategy)\n",
    "\n",
    "#         self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "#             gpytorch.kernels.RBFKernel(\n",
    "#                 lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(\n",
    "#                     math.exp(-1), math.exp(1), sigma=0.1, transform=torch.exp\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#         self.mean_module = gpytorch.means.ConstantMean()\n",
    "#         self.grid_bounds = grid_bounds\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         mean = self.mean_module(x)\n",
    "#         covar = self.covar_module(x)\n",
    "#         return gpytorch.distributions.Normal(mean, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf91392-b8d2-437a-a8f8-b251b0843fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "\n",
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8454aa6a-9d20-41a1-b8fc-d085eb2fda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproximateDKLRegression(gpytorch.Module):\n",
    "    def __init__(self, inducing_points, num_dim=50, grid_bounds=(-1., 1.)):\n",
    "        super(ApproximateDKLRegression, self).__init__()\n",
    "        self.feature_extractor = BaseCNN()\n",
    "        self.gp_layer = GPModel(inducing_points)\n",
    "        self.grid_bounds = grid_bounds\n",
    "        self.num_dim = num_dim\n",
    "\n",
    "        # This module will scale the NN features so that they're nice values\n",
    "        self.scale_to_bounds = gpytorch.utils.grid.ScaleToBounds(self.grid_bounds[0], self.grid_bounds[1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        features = self.scale_to_bounds(features)\n",
    "        # This next line makes it so that we learn a GP for each feature\n",
    "        #features = features.transpose(-1, -2).unsqueeze(-1)\n",
    "        res = self.gp_layer(features)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b560e3e-2486-47a5-9aed-60fae9af5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = BaseCNN().double().cuda()\n",
    "inducing_points = mm(next(iter(train_dataloader))[0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6997f-1367-4e06-8bbe-d91e2b4d2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.train()\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()    \n",
    "        examples, labels = batch     \n",
    "    \n",
    "        predictions = model(examples).reshape(-1)\n",
    "\n",
    "        loss = criterion(predictions, labels.double())\n",
    "\n",
    "        loss.double().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d46eec-d55f-4b49-8f8e-3a57732bc2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "model = ApproximateDKLRegression(inducing_points).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "363c0929-b1d1-406e-8021-c1f5ee1906e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "lr = 0.001\n",
    "optimizer = Adam([\n",
    "    {'params': model.feature_extractor.parameters()},\n",
    "    {'params': model.gp_layer.hyperparameters(), 'lr': lr * 0.01},\n",
    "    {'params': model.gp_layer.variational_parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=lr)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[0.5 * n_epochs, 0.75 * n_epochs], gamma=0.1)\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model.gp_layer, num_data=len(train_dataloader.dataset))\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    minibatch_iter = tqdm.notebook.tqdm(train_dataloader, desc=f\"(Epoch {epoch}) Minibatch\")\n",
    "    with gpytorch.settings.num_likelihood_samples(8):\n",
    "        for data, target in minibatch_iter:\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = -mll(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            minibatch_iter.set_postfix(loss=loss.item())\n",
    "        \n",
    "def test():\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    means = torch.tensor([0.])\n",
    "    test_y = torch.tensor([0.])\n",
    "    with torch.no_grad(), gpytorch.settings.num_likelihood_samples(16):\n",
    "        for data, target in test_dataloader:\n",
    "\n",
    "            preds = model(data)\n",
    "            means = torch.cat([means, preds.mean.cpu()])\n",
    "            test_y = torch.cat([test_y, target.cpu()])\n",
    "    means = means[1:]\n",
    "    test_y = test_y[1:]\n",
    "    print('Test MSE: {}'.format(torch.mean((means - test_y.cpu()) ** 2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "970821c1-8107-40e0-8669-f388d19e99af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676fa95231d543b38ffcd6cb611eabdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(Epoch 1) Minibatch:   0%|          | 0/1865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.143752619293364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707d2858f64c4eeaa9f433d8e12e8b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(Epoch 2) Minibatch:   0%|          | 0/1865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.14375604097763667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c30da884d6e4b389203dcdc468c9502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(Epoch 3) Minibatch:   0%|          | 0/1865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16752/3110171584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_toeplitz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16752/295830632.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mminibatch_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    with gpytorch.settings.use_toeplitz(False):\n",
    "        train(epoch)\n",
    "        test()\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
