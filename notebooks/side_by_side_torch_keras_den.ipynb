{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to debug the torch transfer of weights, we're gonna side by side compare the forward passes of the two models... :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with loading keras generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# point path to genesis repo\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    '/gpfs/commons/home/tchen/al_project/genesis/analysis/splicing'\n",
    ")\n",
    "from definitions.generator.splirent_deconv_conv_generator_concat import load_generator_network\n",
    "from genesis.generator import build_generator, st_sampled_softmax, st_hardmax_softmax\n",
    "from pathlib import Path\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Concatenate, Reshape, Softmax, Conv2DTranspose\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 12:55:30.572975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799950000 Hz\n",
      "2024-03-12 12:55:30.573999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55654fc66e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-12 12:55:30.574025: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/genesis/generator/genesis_generator.py:26: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/genesis/generator/genesis_generator.py:28: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'genesis_splicing_cnn_target_isoform_00_pwm_and_multisample_hek_only_random_regions_50_epochs_harderentropy_generator.h5'\n",
    "model_save_dir = '/gpfs/commons/groups/knowles_lab/ting/DEN_splicing_pretrained_models/'\n",
    "\n",
    "full_path = model_save_dir + model_name\n",
    "generator_model = load_model(filepath=str(full_path), custom_objects={'K': K, 'st_sampled_softmax': st_sampled_softmax, 'st_hardmax_softmax': st_hardmax_softmax}, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the torch model with the previously saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# point path to our repo\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    '/gpfs/commons/home/tchen/al_project/active-learning-cnns-gps/src'\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from models.den import Generator\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/gpfs/commons/groups/knowles_lab/ting/DEN_splicing_generator_weights/'\n",
    "save_name = 'target_isoform_00.npy'\n",
    "\n",
    "target_isoform_net_weights = np.load(save_path+save_name, allow_pickle=True)\n",
    "\n",
    "# list of numpy arrays\n",
    "weights = target_isoform_net_weights.tolist()\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# need to extract embedding template and mask from pretrained network\n",
    "pretrained_embedding_template = torch.tensor(weights[-2]).to(device)\n",
    "pretrained_embedding_mask = torch.tensor(weights[-1]).to(device)\n",
    "\n",
    "n_samples = 10\n",
    "n_classes = 1\n",
    "seq_length = 109\n",
    "latent_dim = 100\n",
    "batch_size = 32\n",
    "\n",
    "torch_generator = Generator(embedding_template=pretrained_embedding_template,\n",
    "                                   embedding_mask=pretrained_embedding_mask,\n",
    "                                   device=device,\n",
    "                                   latent_dim=latent_dim,\n",
    "                                   batch_size=batch_size,\n",
    "                                   seq_length=seq_length,\n",
    "                                   n_classes=n_classes,\n",
    "                                   n_samples=n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "running_keras_weight_idx = 0\n",
    "\n",
    "for i, layer in enumerate(torch_generator.generator_network.generator_network):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        # transfer linear layer weights and biases\n",
    "        assert tuple(layer.weight.data.shape) == weights[running_keras_weight_idx].T.shape\n",
    "        layer.weight.data = torch.from_numpy(weights[running_keras_weight_idx].T)\n",
    "        running_keras_weight_idx += 1\n",
    "\n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.ConvTranspose2d):\n",
    "        # transfer convtranspose2d weights and biases\n",
    "        assert tuple(layer.weight.shape) == np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]).shape\n",
    "        layer.weight.data = torch.from_numpy(np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]))\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.Conv2d):\n",
    "        # transfer conv2d weights and biases\n",
    "        assert tuple(layer.weight.data.shape) == np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]).shape\n",
    "        layer.weight.data = torch.from_numpy(np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]))\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.BatchNorm2d):\n",
    "        # transfer batch norm gamma, beta, running mean, running variance\n",
    "        # order from keras model should be gamma, beta, moving mean, moving variance\n",
    "        assert tuple(layer.weight.data.shape) == weights[running_keras_weight_idx].shape # this might need a transpose\n",
    "        layer.weight.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.running_mean.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.running_mean.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.running_var.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.running_var.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (generator_network): GeneratorNetwork(\n",
       "    (generator_network): ModuleList(\n",
       "      (0): Linear(in_features=101, out_features=3456, bias=True)\n",
       "      (1): ConvTranspose2d(384, 256, kernel_size=(7, 1), stride=(2, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (3): ConvTranspose2d(256, 192, kernel_size=(8, 1), stride=(2, 1))\n",
       "      (4): BatchNorm2d(192, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (5): ConvTranspose2d(192, 128, kernel_size=(7, 1), stride=(2, 1))\n",
       "      (6): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (9): Conv2d(128, 64, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "      (10): BatchNorm2d(64, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (11): Conv2d(64, 4, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "    )\n",
       "  )\n",
       "  (onehot_template_layer): Embedding(1, 436)\n",
       "  (onehot_mask_layer): Embedding(1, 436)\n",
       "  (straight_through): StraightThroughEstimator()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_generator.to(device)\n",
    "torch_generator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now we'll start with the same input and layer by layer compare the outputs of the keras model with the outputs of the torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator forward loop (up until generator network)\n",
    "\n",
    "# Seed class input for all dense/embedding layers\n",
    "sequence_class = torch.empty(batch_size).to(device)\n",
    "\n",
    "# TODO: Super jank, refactor this...\n",
    "sequence_class.uniform_(-0.499, 1-0.5001)\n",
    "sequence_class = torch.round(sequence_class).int()\n",
    "# sequence_class = torch.ones(self.batch_size, dtype=torch.int32).to(self.device)\n",
    "\n",
    "# Get generated policy pwm logits (non-masked)\n",
    "# latent_input_1 = torch.empty((batch_size, latent_dim)).to(device)\n",
    "# latent_input_2 = torch.empty((batch_size, latent_dim)).to(device)\n",
    "latent_input_1 = torch.ones((batch_size, latent_dim)).to(device)\n",
    "latent_input_2 = torch.ones((batch_size, latent_dim)).to(device)\n",
    "\n",
    "# latent_input_1.uniform_(-1.0, 1.0)\n",
    "# latent_input_2.uniform_(-1.0, 1.0)\n",
    "\n",
    "sequence_class_onehots = torch.eye(1).to(device)\n",
    "\n",
    "# check here for bugs\n",
    "class_embedding = sequence_class_onehots.index_select(0, index=sequence_class)    # tf.gather equivalent\n",
    "# class_embedding = torch.ones((self.batch_size, 1), dtype=torch.int32).to(self.device)\n",
    "\n",
    "torch_seed_input_1 = torch.cat([latent_input_1, class_embedding], dim=-1)\n",
    "torch_seed_input_2 = torch.cat([latent_input_2, class_embedding], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat same for keras model\n",
    "sequence_class_input = Input(tensor=K.ones((batch_size, 1)), dtype='int32', name='sequence_class_seed')\n",
    "sequence_class = Lambda(lambda inp: K.cast(K.round(inp * K.random_uniform((batch_size, 1), minval=-0.4999, maxval=n_classes-0.5001)), dtype='int32'), name='lambda_rand_sequence_class')(sequence_class_input)\n",
    "\n",
    "sequence_class_onehots = np.eye(n_classes)\n",
    "\n",
    "#Generator network parameters\n",
    "latent_size = 100\n",
    "\n",
    "#Generator inputs\n",
    "latent_input_1 = Input(tensor=K.ones((batch_size, latent_size)), name='noise_input_1')\n",
    "latent_input_2 = Input(tensor=K.ones((batch_size, latent_size)), name='noise_input_2')\n",
    "# latent_input_1_out = Lambda(lambda inp: inp * K.random_uniform((batch_size, latent_size), minval=-1.0, maxval=1.0), name='lambda_rand_input_1')(latent_input_1)\n",
    "# latent_input_2_out = Lambda(lambda inp: inp * K.random_uniform((batch_size, latent_size), minval=-1.0, maxval=1.0), name='lambda_rand_input_2')(latent_input_2)\n",
    "\n",
    "class_embedding = Lambda(lambda x: K.gather(K.constant(sequence_class_onehots), K.cast(x[:, 0], dtype='int32')))(sequence_class)\n",
    "\n",
    "keras_seed_input_1 = Concatenate(axis=-1)([latent_input_1, class_embedding])\n",
    "keras_seed_input_2 = Concatenate(axis=-1)([latent_input_2, class_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function([sequence_class_input, latent_input_1, latent_input_2], [keras_seed_input_1, keras_seed_input_2])\n",
    "keras_sequence_class = func([K.ones((batch_size, 1)), K.ones((batch_size, latent_size)), K.ones((batch_size, latent_size))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good so far from here, let's start testing the generator networks layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dense_output = F.relu(torch_generator.generator_network.generator_network[0](torch_seed_input_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dense layer weights over\n",
    "layer_input = Input(shape=(latent_dim+1,))\n",
    "copy_dense_1 = Dense(9 * 384, activation='relu', kernel_initializer='glorot_uniform', name='policy_dense_1')\n",
    "out = copy_dense_1(layer_input)\n",
    "model = Model(inputs=layer_input, outputs=out)\n",
    "copy_dense_1.set_weights(generator_model.get_layer('policy_dense_1').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_dense_output = model.predict(keras_sequence_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(torch_dense_output.detach().numpy(), keras_dense_output, rtol=1e-03) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First dense layer passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvTranspose2d(384, 256, kernel_size=(7, 1), stride=(2, 1))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_generator.generator_network.generator_network[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_deconv_0_output = torch_generator.generator_network.generator_network[1](torch_dense_output.view(batch_size, 384, 9, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  6.5826],\n",
       "          [ -1.9226],\n",
       "          [  1.5328],\n",
       "          ...,\n",
       "          [-10.2842],\n",
       "          [ -4.4818],\n",
       "          [ -4.3741]],\n",
       "\n",
       "         [[ -5.2752],\n",
       "          [  1.5402],\n",
       "          [ -9.7774],\n",
       "          ...,\n",
       "          [-17.4850],\n",
       "          [-13.4211],\n",
       "          [ -7.0050]],\n",
       "\n",
       "         [[ -2.1654],\n",
       "          [  8.2707],\n",
       "          [-13.3770],\n",
       "          ...,\n",
       "          [-12.9350],\n",
       "          [  4.1130],\n",
       "          [ -0.6644]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -7.1633],\n",
       "          [  4.9998],\n",
       "          [ -4.7229],\n",
       "          ...,\n",
       "          [ -0.5790],\n",
       "          [ -3.8544],\n",
       "          [  0.5504]],\n",
       "\n",
       "         [[ -0.4081],\n",
       "          [ -3.9280],\n",
       "          [  3.7245],\n",
       "          ...,\n",
       "          [-30.1781],\n",
       "          [ -3.3762],\n",
       "          [-19.1783]],\n",
       "\n",
       "         [[-11.1019],\n",
       "          [  6.2191],\n",
       "          [ -5.6924],\n",
       "          ...,\n",
       "          [ 19.4362],\n",
       "          [ -2.9812],\n",
       "          [ 16.9553]]],\n",
       "\n",
       "\n",
       "        [[[  6.5826],\n",
       "          [ -1.9226],\n",
       "          [  1.5328],\n",
       "          ...,\n",
       "          [-10.2842],\n",
       "          [ -4.4818],\n",
       "          [ -4.3741]],\n",
       "\n",
       "         [[ -5.2752],\n",
       "          [  1.5402],\n",
       "          [ -9.7774],\n",
       "          ...,\n",
       "          [-17.4850],\n",
       "          [-13.4211],\n",
       "          [ -7.0050]],\n",
       "\n",
       "         [[ -2.1654],\n",
       "          [  8.2707],\n",
       "          [-13.3770],\n",
       "          ...,\n",
       "          [-12.9350],\n",
       "          [  4.1130],\n",
       "          [ -0.6644]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -7.1633],\n",
       "          [  4.9998],\n",
       "          [ -4.7229],\n",
       "          ...,\n",
       "          [ -0.5790],\n",
       "          [ -3.8544],\n",
       "          [  0.5504]],\n",
       "\n",
       "         [[ -0.4081],\n",
       "          [ -3.9280],\n",
       "          [  3.7245],\n",
       "          ...,\n",
       "          [-30.1781],\n",
       "          [ -3.3762],\n",
       "          [-19.1783]],\n",
       "\n",
       "         [[-11.1019],\n",
       "          [  6.2191],\n",
       "          [ -5.6924],\n",
       "          ...,\n",
       "          [ 19.4362],\n",
       "          [ -2.9812],\n",
       "          [ 16.9553]]],\n",
       "\n",
       "\n",
       "        [[[  6.5826],\n",
       "          [ -1.9226],\n",
       "          [  1.5328],\n",
       "          ...,\n",
       "          [-10.2842],\n",
       "          [ -4.4818],\n",
       "          [ -4.3741]],\n",
       "\n",
       "         [[ -5.2752],\n",
       "          [  1.5402],\n",
       "          [ -9.7774],\n",
       "          ...,\n",
       "          [-17.4850],\n",
       "          [-13.4211],\n",
       "          [ -7.0050]],\n",
       "\n",
       "         [[ -2.1654],\n",
       "          [  8.2707],\n",
       "          [-13.3770],\n",
       "          ...,\n",
       "          [-12.9350],\n",
       "          [  4.1130],\n",
       "          [ -0.6644]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -7.1633],\n",
       "          [  4.9998],\n",
       "          [ -4.7229],\n",
       "          ...,\n",
       "          [ -0.5790],\n",
       "          [ -3.8544],\n",
       "          [  0.5504]],\n",
       "\n",
       "         [[ -0.4081],\n",
       "          [ -3.9280],\n",
       "          [  3.7245],\n",
       "          ...,\n",
       "          [-30.1781],\n",
       "          [ -3.3762],\n",
       "          [-19.1783]],\n",
       "\n",
       "         [[-11.1019],\n",
       "          [  6.2191],\n",
       "          [ -5.6924],\n",
       "          ...,\n",
       "          [ 19.4362],\n",
       "          [ -2.9812],\n",
       "          [ 16.9553]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  6.5826],\n",
       "          [ -1.9226],\n",
       "          [  1.5328],\n",
       "          ...,\n",
       "          [-10.2842],\n",
       "          [ -4.4818],\n",
       "          [ -4.3741]],\n",
       "\n",
       "         [[ -5.2752],\n",
       "          [  1.5402],\n",
       "          [ -9.7774],\n",
       "          ...,\n",
       "          [-17.4850],\n",
       "          [-13.4211],\n",
       "          [ -7.0050]],\n",
       "\n",
       "         [[ -2.1654],\n",
       "          [  8.2707],\n",
       "          [-13.3770],\n",
       "          ...,\n",
       "          [-12.9350],\n",
       "          [  4.1130],\n",
       "          [ -0.6644]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -7.1633],\n",
       "          [  4.9998],\n",
       "          [ -4.7229],\n",
       "          ...,\n",
       "          [ -0.5790],\n",
       "          [ -3.8544],\n",
       "          [  0.5504]],\n",
       "\n",
       "         [[ -0.4081],\n",
       "          [ -3.9280],\n",
       "          [  3.7245],\n",
       "          ...,\n",
       "          [-30.1781],\n",
       "          [ -3.3762],\n",
       "          [-19.1783]],\n",
       "\n",
       "         [[-11.1019],\n",
       "          [  6.2191],\n",
       "          [ -5.6924],\n",
       "          ...,\n",
       "          [ 19.4362],\n",
       "          [ -2.9812],\n",
       "          [ 16.9553]]],\n",
       "\n",
       "\n",
       "        [[[  6.5826],\n",
       "          [ -1.9226],\n",
       "          [  1.5328],\n",
       "          ...,\n",
       "          [-10.2842],\n",
       "          [ -4.4818],\n",
       "          [ -4.3741]],\n",
       "\n",
       "         [[ -5.2752],\n",
       "          [  1.5402],\n",
       "          [ -9.7774],\n",
       "          ...,\n",
       "          [-17.4850],\n",
       "          [-13.4211],\n",
       "          [ -7.0050]],\n",
       "\n",
       "         [[ -2.1654],\n",
       "          [  8.2707],\n",
       "          [-13.3770],\n",
       "          ...,\n",
       "          [-12.9350],\n",
       "          [  4.1130],\n",
       "          [ -0.6644]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -7.1633],\n",
       "          [  4.9998],\n",
       "          [ -4.7229],\n",
       "          ...,\n",
       "          [ -0.5790],\n",
       "          [ -3.8544],\n",
       "          [  0.5504]],\n",
       "\n",
       "         [[ -0.4081],\n",
       "          [ -3.9280],\n",
       "          [  3.7245],\n",
       "          ...,\n",
       "          [-30.1781],\n",
       "          [ -3.3762],\n",
       "          [-19.1783]],\n",
       "\n",
       "         [[-11.1019],\n",
       "          [  6.2191],\n",
       "          [ -5.6924],\n",
       "          ...,\n",
       "          [ 19.4362],\n",
       "          [ -2.9812],\n",
       "          [ 16.9553]]],\n",
       "\n",
       "\n",
       "        [[[  6.5826],\n",
       "          [ -1.9226],\n",
       "          [  1.5328],\n",
       "          ...,\n",
       "          [-10.2842],\n",
       "          [ -4.4818],\n",
       "          [ -4.3741]],\n",
       "\n",
       "         [[ -5.2752],\n",
       "          [  1.5402],\n",
       "          [ -9.7774],\n",
       "          ...,\n",
       "          [-17.4850],\n",
       "          [-13.4211],\n",
       "          [ -7.0050]],\n",
       "\n",
       "         [[ -2.1654],\n",
       "          [  8.2707],\n",
       "          [-13.3770],\n",
       "          ...,\n",
       "          [-12.9350],\n",
       "          [  4.1130],\n",
       "          [ -0.6644]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -7.1633],\n",
       "          [  4.9998],\n",
       "          [ -4.7229],\n",
       "          ...,\n",
       "          [ -0.5790],\n",
       "          [ -3.8544],\n",
       "          [  0.5504]],\n",
       "\n",
       "         [[ -0.4081],\n",
       "          [ -3.9280],\n",
       "          [  3.7245],\n",
       "          ...,\n",
       "          [-30.1781],\n",
       "          [ -3.3762],\n",
       "          [-19.1783]],\n",
       "\n",
       "         [[-11.1019],\n",
       "          [  6.2191],\n",
       "          [ -5.6924],\n",
       "          ...,\n",
       "          [ 19.4362],\n",
       "          [ -2.9812],\n",
       "          [ 16.9553]]]], grad_fn=<SlowConvTranspose2DBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_deconv_0_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_input = Input(shape=(9*384,))\n",
    "policy_dense_1_reshape = Reshape((9, 1, 384))\n",
    "policy_deconv_0 = Conv2DTranspose(256, (7, 1), strides=(2, 1), padding='valid', activation='linear', kernel_initializer='glorot_normal', name='policy_deconv_0', input_shape=(9, 1, 384), data_format='channels_last')\n",
    "out_reshape = policy_dense_1_reshape(layer_input)\n",
    "out = policy_deconv_0(out_reshape)\n",
    "model = Model(inputs=layer_input, outputs=[out, out_reshape])\n",
    "policy_deconv_0.set_weights(generator_model.get_layer('policy_deconv_0').get_weights())\n",
    "keras_deconv_0_output = model.predict(keras_dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check after reshape\n",
    "np.testing.assert_allclose(keras_deconv_0_output[-1], torch_dense_output.view(batch_size, 9, 1, 384).detach().numpy(), rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_deconv_0_output.detach().numpy().shape == keras_deconv_0_output[0].transpose([0, 3, 1, 2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=0\n\nMismatched elements: 188192 / 188416 (99.9%)\nMax absolute difference: 57.362293\nMax relative difference: 850.39166\n x: array([[[[  6.582626],\n         [ -1.922581],\n         [  1.532797],...\n y: array([[[[ 2.139414e+00],\n         [-3.674752e-03],\n         [ 5.357710e+00],...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_17559/4164615920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_deconv_0_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_deconv_0_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    844\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=0\n\nMismatched elements: 188192 / 188416 (99.9%)\nMax absolute difference: 57.362293\nMax relative difference: 850.39166\n x: array([[[[  6.582626],\n         [ -1.922581],\n         [  1.532797],...\n y: array([[[[ 2.139414e+00],\n         [-3.674752e-03],\n         [ 5.357710e+00],..."
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(torch_deconv_0_output.detach().numpy(), keras_deconv_0_output[0].transpose([0, 3, 1, 2]), rtol=1e-3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the error was in the conv2dTranspose..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_0 = nn.ConvTranspose2d(in_channels=384, out_channels=256, kernel_size=(7, 1), stride=(2, 1), bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert deconv_0.weight.shape == np.transpose(generator_model.get_layer('policy_deconv_0').get_weights()[0], axes=[3, 2, 0, 1]).shape\n",
    "deconv_0.weight.data = torch.from_numpy(np.transpose(generator_model.get_layer('policy_deconv_0').get_weights()[0], axes=[3, 2, 0, 1]))\n",
    "deconv_0.bias.data = torch.from_numpy(generator_model.get_layer('policy_deconv_0').get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1, 256, 384)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_model.get_layer('policy_deconv_0').get_weights()[0].shape # kernel height, width, out channels, in channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator_model.get_layer('policy_deconv_0').compute_output_shape((32, 9, 1, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 256, 7, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconv_0.weight.shape # in channels, out channels, kernel height, kernel width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check weights are equal\n",
    "np.testing.assert_allclose(torch_generator.generator_network.generator_network[1].weight.detach().numpy(), policy_deconv_0.get_weights()[0].transpose([3, 2, 0, 1])) \n",
    "np.testing.assert_allclose(torch_generator.generator_network.generator_network[1].bias.detach().numpy(), policy_deconv_0.get_weights()[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with ones as input\n",
    "\n",
    "keras_test_ones_output = model.predict(np.ones((32, 9*384)))\n",
    "torch_test_ones_output = torch_generator.generator_network.generator_network[1](torch.ones((32, 384, 9, 1)))\n",
    "np.testing.assert_allclose(torch_test_ones_output.detach().numpy().transpose(0, 2, 3, 1), keras_test_ones_output[0], rtol=1e-03) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with ones as input\n",
    "\n",
    "keras_test_ones_output = model.predict(np.ones((32, 9*384)))\n",
    "torch_test_ones_output = deconv_0(torch.ones((32, 384, 9, 1)))\n",
    "np.testing.assert_allclose(torch_test_ones_output.detach().numpy().transpose(0, 2, 3, 1), keras_test_ones_output[0], rtol=1e-03) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_generator.generator_network.generator_network[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-05, atol=0\n\nMismatched elements: 188416 / 188416 (100%)\nMax absolute difference: 37.82418\nMax relative difference: 101483.47\n x: array([[[[  5.396858,   3.702867,   3.895614, ...,   2.196572,\n            1.287122,   2.091106]],\n...\n y: array([[[[ -5.685665,  -1.733513,  -6.924087, ...,   1.014218,\n            5.29361 ,  -0.489688]],\n...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_17559/1497791474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkeras_test_rand_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch_test_rand_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_network\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_test_rand_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_test_rand_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    844\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-05, atol=0\n\nMismatched elements: 188416 / 188416 (100%)\nMax absolute difference: 37.82418\nMax relative difference: 101483.47\n x: array([[[[  5.396858,   3.702867,   3.895614, ...,   2.196572,\n            1.287122,   2.091106]],\n...\n y: array([[[[ -5.685665,  -1.733513,  -6.924087, ...,   1.014218,\n            5.29361 ,  -0.489688]],\n..."
     ]
    }
   ],
   "source": [
    "# test with random normal as input\n",
    "rand_input = np.random.normal(size=(32, 9 * 384))\n",
    "keras_test_rand_output = model.predict(rand_input)\n",
    "torch_test_rand_output = torch_generator.generator_network.generator_network[1](torch.from_numpy(rand_input).view((32, 384, 9, 1)).float())\n",
    "np.testing.assert_allclose(torch_test_rand_output.detach().numpy().transpose(0, 2, 3, 1), keras_test_rand_output[0], rtol=1e-05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with random normal as input\n",
    "rand_input = np.random.normal(size=(32, 9 * 384))\n",
    "keras_test_rand_output = model.predict(rand_input)\n",
    "torch_test_rand_output = deconv_0(torch.from_numpy(rand_input.reshape(32, 384, 9, 1)).float())\n",
    "np.testing.assert_allclose(torch_test_rand_output.detach().permute(0, 2, 3, 1).numpy(), keras_test_rand_output[0], rtol=1e-05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[[1.0, 1.0, 1.0], [2.0, 1.0, 1.0]], [[2.0, 1.0, 1.0], [1.0, 1.0, 0.0]],  [[2.0, 2.0, 2.0], [1.0, 1.0, 1.0]]])\n",
    "X = X.reshape(1, 3, 2, 3)\n",
    "weights = [np.asarray([[[[1, 0, 1], [1, 0, 1]]], [[[1, 0, 1], [1, 0, 1]]],  [[[1, 0, 1], [1, 0, 1]]]]), np.asarray([2, 2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 1., 1.],\n",
       "         [2., 1., 1.]],\n",
       "\n",
       "        [[2., 1., 1.],\n",
       "         [1., 1., 0.]],\n",
       "\n",
       "        [[2., 2., 2.],\n",
       "         [1., 1., 1.]]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1, 0, 1],\n",
       "         [1, 0, 1]]],\n",
       "\n",
       "\n",
       "       [[[1, 0, 1],\n",
       "         [1, 0, 1]]],\n",
       "\n",
       "\n",
       "       [[[1, 0, 1],\n",
       "         [1, 0, 1]]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 2, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 3, 1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].transpose(0, 2, 3, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 3, 1]) torch.Size([3, 2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "torch_dummy = nn.ConvTranspose2d(in_channels=3, out_channels=2, kernel_size=(3, 1), stride=(2, 1), bias=True)\n",
    "print(torch_dummy.weight.data.shape, torch.from_numpy(weights[0].transpose(3, 2, 0, 1)).float().shape)\n",
    "assert torch_dummy.weight.data.shape ==  torch.from_numpy(weights[0].transpose(3, 2, 0, 1)).float().shape\n",
    "torch_dummy.weight.data = torch.from_numpy(weights[0].transpose(3, 2, 0, 1)).float()\n",
    "torch_dummy.bias.data = torch.from_numpy(weights[1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5.],\n",
       "        [5., 5., 5.],\n",
       "        [8., 7., 7.],\n",
       "        [5., 4., 4.],\n",
       "        [5., 4., 4.]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dummy(torch.from_numpy(X).float())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_input = Input(shape=(3, 2, 3,))\n",
    "reshape = Reshape((2, 3, 3))\n",
    "conv = keras.layers.Conv2DTranspose(2, (3, 1), strides=(2, 1), padding='valid', activation='linear', kernel_initializer='glorot_normal')\n",
    "out = conv(reshape(layer_input))\n",
    "\n",
    "model_Conv2D = Model(layer_input, out)\n",
    "conv.set_weights(weights)\n",
    "yhat = model_Conv2D.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 5., 5.],\n",
       "       [4., 5., 5.],\n",
       "       [5., 9., 7.],\n",
       "       [3., 6., 4.],\n",
       "       [3., 6., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.reshape(5, 3, 2)[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=0\n\nMismatched elements: 26 / 30 (86.7%)\nMax absolute difference: 6.\nMax relative difference: 2.\n x: array([[[4., 4.],\n        [5., 5.],\n        [5., 5.]],...\n y: array([[[ 7.,  7.],\n        [ 6.,  6.],\n        [ 6.,  6.]],...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_17559/3014421863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dummy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    844\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-07, atol=0\n\nMismatched elements: 26 / 30 (86.7%)\nMax absolute difference: 6.\nMax relative difference: 2.\n x: array([[[4., 4.],\n        [5., 5.],\n        [5., 5.]],...\n y: array([[[ 7.,  7.],\n        [ 6.,  6.],\n        [ 6.,  6.]],..."
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(yhat.reshape(5, 3, 2), torch_dummy(torch.from_numpy(X).float()).permute(0, 2, 3, 1).squeeze().detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "combined_pytorch_keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
