{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to debug the torch transfer of weights, we're gonna side by side compare the forward passes of the two models... :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with loading keras generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# point path to genesis repo\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    '/gpfs/commons/home/tchen/al_project/genesis/analysis/splicing'\n",
    ")\n",
    "from definitions.generator.splirent_deconv_conv_generator_concat import load_generator_network\n",
    "from genesis.generator import build_generator, st_sampled_softmax, st_hardmax_softmax\n",
    "from pathlib import Path\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Concatenate, Reshape, Softmax, Conv2DTranspose\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 11:19:46.052089: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2024-03-11 11:19:46.062517: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz\n",
      "2024-03-11 11:19:46.064659: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5599d4b78d70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-11 11:19:46.064693: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/genesis/generator/genesis_generator.py:26: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/genesis/generator/genesis_generator.py:28: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'genesis_splicing_cnn_target_isoform_00_pwm_and_multisample_hek_only_random_regions_50_epochs_harderentropy_generator.h5'\n",
    "model_save_dir = '/gpfs/commons/groups/knowles_lab/ting/DEN_splicing_pretrained_models/'\n",
    "\n",
    "full_path = model_save_dir + model_name\n",
    "generator_model = load_model(filepath=str(full_path), custom_objects={'K': K, 'st_sampled_softmax': st_sampled_softmax, 'st_hardmax_softmax': st_hardmax_softmax}, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the torch model with the previously saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# point path to our repo\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    '/gpfs/commons/home/tchen/al_project/active-learning-cnns-gps/src'\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from models.den import Generator\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/gpfs/commons/groups/knowles_lab/ting/DEN_splicing_generator_weights/'\n",
    "save_name = 'target_isoform_00.npy'\n",
    "\n",
    "target_isoform_net_weights = np.load(save_path+save_name, allow_pickle=True)\n",
    "\n",
    "# list of numpy arrays\n",
    "weights = target_isoform_net_weights.tolist()\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# need to extract embedding template and mask from pretrained network\n",
    "pretrained_embedding_template = torch.tensor(weights[-2]).to(device)\n",
    "pretrained_embedding_mask = torch.tensor(weights[-1]).to(device)\n",
    "\n",
    "n_samples = 10\n",
    "n_classes = 1\n",
    "seq_length = 109\n",
    "latent_dim = 100\n",
    "batch_size = 32\n",
    "\n",
    "torch_generator = Generator(embedding_template=pretrained_embedding_template,\n",
    "                                   embedding_mask=pretrained_embedding_mask,\n",
    "                                   device=device,\n",
    "                                   latent_dim=latent_dim,\n",
    "                                   batch_size=batch_size,\n",
    "                                   seq_length=seq_length,\n",
    "                                   n_classes=n_classes,\n",
    "                                   n_samples=n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "running_keras_weight_idx = 0\n",
    "\n",
    "for i, layer in enumerate(torch_generator.generator_network.generator_network):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        # transfer linear layer weights and biases\n",
    "        assert tuple(layer.weight.data.shape) == weights[running_keras_weight_idx].T.shape\n",
    "        layer.weight.data = torch.from_numpy(weights[running_keras_weight_idx].T)\n",
    "        running_keras_weight_idx += 1\n",
    "\n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.ConvTranspose2d):\n",
    "        # transfer convtranspose2d weights and biases\n",
    "        assert tuple(layer.weight.data.shape) == np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]).shape\n",
    "        layer.weight.data = torch.from_numpy(np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]))\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.Conv2d):\n",
    "        # transfer conv2d weights and biases\n",
    "        assert tuple(layer.weight.data.shape) == np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]).shape\n",
    "        layer.weight.data = torch.from_numpy(np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]))\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.BatchNorm2d):\n",
    "        # transfer batch norm gamma, beta, running mean, running variance\n",
    "        # order from keras model should be gamma, beta, moving mean, moving variance\n",
    "        assert tuple(layer.weight.data.shape) == weights[running_keras_weight_idx].shape # this might need a transpose\n",
    "        layer.weight.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.running_mean.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.running_mean.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.running_var.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.running_var.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (generator_network): GeneratorNetwork(\n",
       "    (generator_network): ModuleList(\n",
       "      (0): Linear(in_features=101, out_features=3456, bias=True)\n",
       "      (1): ConvTranspose2d(384, 256, kernel_size=(7, 1), stride=(2, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (3): ConvTranspose2d(256, 192, kernel_size=(8, 1), stride=(2, 1))\n",
       "      (4): BatchNorm2d(192, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (5): ConvTranspose2d(192, 128, kernel_size=(7, 1), stride=(2, 1))\n",
       "      (6): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (9): Conv2d(128, 64, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "      (10): BatchNorm2d(64, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (11): Conv2d(64, 4, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "    )\n",
       "  )\n",
       "  (onehot_template_layer): Embedding(1, 436)\n",
       "  (onehot_mask_layer): Embedding(1, 436)\n",
       "  (straight_through): StraightThroughEstimator()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_generator.to(device)\n",
    "torch_generator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now we'll start with the same input and layer by layer compare the outputs of the keras model with the outputs of the torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator forward loop (up until generator network)\n",
    "\n",
    "# Seed class input for all dense/embedding layers\n",
    "sequence_class = torch.empty(batch_size).to(device)\n",
    "\n",
    "# TODO: Super jank, refactor this...\n",
    "sequence_class.uniform_(-0.499, 1-0.5001)\n",
    "sequence_class = torch.round(sequence_class).int()\n",
    "# sequence_class = torch.ones(self.batch_size, dtype=torch.int32).to(self.device)\n",
    "\n",
    "# Get generated policy pwm logits (non-masked)\n",
    "# latent_input_1 = torch.empty((batch_size, latent_dim)).to(device)\n",
    "# latent_input_2 = torch.empty((batch_size, latent_dim)).to(device)\n",
    "latent_input_1 = torch.ones((batch_size, latent_dim)).to(device)\n",
    "latent_input_2 = torch.ones((batch_size, latent_dim)).to(device)\n",
    "\n",
    "# latent_input_1.uniform_(-1.0, 1.0)\n",
    "# latent_input_2.uniform_(-1.0, 1.0)\n",
    "\n",
    "sequence_class_onehots = torch.eye(1).to(device)\n",
    "\n",
    "# check here for bugs\n",
    "class_embedding = sequence_class_onehots.index_select(0, index=sequence_class)    # tf.gather equivalent\n",
    "# class_embedding = torch.ones((self.batch_size, 1), dtype=torch.int32).to(self.device)\n",
    "\n",
    "torch_seed_input_1 = torch.cat([latent_input_1, class_embedding], dim=-1)\n",
    "torch_seed_input_2 = torch.cat([latent_input_2, class_embedding], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat same for keras model\n",
    "sequence_class_input = Input(tensor=K.ones((batch_size, 1)), dtype='int32', name='sequence_class_seed')\n",
    "sequence_class = Lambda(lambda inp: K.cast(K.round(inp * K.random_uniform((batch_size, 1), minval=-0.4999, maxval=n_classes-0.5001)), dtype='int32'), name='lambda_rand_sequence_class')(sequence_class_input)\n",
    "\n",
    "sequence_class_onehots = np.eye(n_classes)\n",
    "\n",
    "#Generator network parameters\n",
    "latent_size = 100\n",
    "\n",
    "#Generator inputs\n",
    "latent_input_1 = Input(tensor=K.ones((batch_size, latent_size)), name='noise_input_1')\n",
    "latent_input_2 = Input(tensor=K.ones((batch_size, latent_size)), name='noise_input_2')\n",
    "# latent_input_1_out = Lambda(lambda inp: inp * K.random_uniform((batch_size, latent_size), minval=-1.0, maxval=1.0), name='lambda_rand_input_1')(latent_input_1)\n",
    "# latent_input_2_out = Lambda(lambda inp: inp * K.random_uniform((batch_size, latent_size), minval=-1.0, maxval=1.0), name='lambda_rand_input_2')(latent_input_2)\n",
    "\n",
    "class_embedding = Lambda(lambda x: K.gather(K.constant(sequence_class_onehots), K.cast(x[:, 0], dtype='int32')))(sequence_class)\n",
    "\n",
    "keras_seed_input_1 = Concatenate(axis=-1)([latent_input_1, class_embedding])\n",
    "keras_seed_input_2 = Concatenate(axis=-1)([latent_input_2, class_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function([sequence_class_input, latent_input_1, latent_input_2], [keras_seed_input_1, keras_seed_input_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_sequence_class = func([K.ones((batch_size, 1)), K.ones((batch_size, latent_size)), K.ones((batch_size, latent_size))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good so far from here, let's start testing the generator networks layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dense_output = F.relu(torch_generator.generator_network.generator_network[0](torch_seed_input_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dense layer weights over\n",
    "layer_input = Input(shape=(latent_dim+1,))\n",
    "copy_dense_1 = Dense(9 * 384, activation='relu', kernel_initializer='glorot_uniform', name='policy_dense_1')\n",
    "out = copy_dense_1(layer_input)\n",
    "model = Model(inputs=layer_input, outputs=out)\n",
    "copy_dense_1.set_weights(generator_model.get_layer('policy_dense_1').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_dense_output = model.predict(keras_sequence_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(torch_dense_output.detach().numpy(), keras_dense_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First dense layer passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_deconv_0_output = torch_generator.generator_network.generator_network[1](torch_dense_output.reshape(batch_size, 384, 9, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_input = Input(shape=(9*384,))\n",
    "policy_dense_1_reshape = Reshape((9, 1, 384))\n",
    "policy_deconv_0 = Conv2DTranspose(256, (7, 1), strides=(2, 1), padding='valid', activation='linear', kernel_initializer='glorot_normal', name='policy_deconv_0')\n",
    "out = policy_deconv_0(policy_dense_1_reshape(layer_input))\n",
    "model = Model(inputs=layer_input, outputs=out)\n",
    "policy_deconv_0.set_weights(generator_model.get_layer('policy_deconv_0').get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_deconv_0_output = model.predict(keras_dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 23, 1, 256)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_deconv_0_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_deconv_0_output.detach().numpy().shape == keras_deconv_0_output.transpose([0, 3, 1, 2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=0\n\nMismatched elements: 188416 / 188416 (100%)\nMax absolute difference: 57.36231\nMax relative difference: 850.8875\n x: array([[[[  6.582627],\n         [ -1.922581],\n         [  1.532796],...\n y: array([[[[ 2.139414e+00],\n         [-3.674655e-03],\n         [ 5.357711e+00],...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_223621/278546794.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_deconv_0_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_deconv_0_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/al_project/combined_pytorch_keras_env/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    844\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-07, atol=0\n\nMismatched elements: 188416 / 188416 (100%)\nMax absolute difference: 57.36231\nMax relative difference: 850.8875\n x: array([[[[  6.582627],\n         [ -1.922581],\n         [  1.532796],...\n y: array([[[[ 2.139414e+00],\n         [-3.674655e-03],\n         [ 5.357711e+00],..."
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(torch_deconv_0_output.detach().numpy(), keras_deconv_0_output.transpose([0, 3, 1, 2])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the error was in the conv2dTranspose..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_0 = nn.ConvTranspose2d(in_channels=384, out_channels=256, kernel_size=(7, 1), stride=(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1, 256, 384)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_model.get_layer('policy_deconv_0').get_weights()[0].shape # kernel height, width, out channels, in channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384, 256, 7, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconv_0.weight.shape # in channels, out channels, kernel height, kernel width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check weights are equal\n",
    "np.testing.assert_allclose(torch_generator.generator_network.generator_network[1].bias.detach().numpy(), generator_model.get_layer('policy_deconv_0').get_weights()[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(torch_generator.generator_network.generator_network[1].weight.detach().numpy(), generator_model.get_layer('policy_deconv_0').get_weights()[0].transpose([3, 2, 0, 1])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "combined_pytorch_keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
