{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with loading in weights to a keras model and then exporting to a PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# point path to genesis repo\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    '/gpfs/commons/home/tchen/al_project/genesis/analysis/splicing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from definitions.generator.splirent_deconv_conv_generator_concat import load_generator_network\n",
    "from genesis.generator import build_generator, st_sampled_softmax, st_hardmax_softmax\n",
    "from pathlib import Path\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'genesis_splicing_cnn_target_isoform_00_pwm_and_multisample_hek_only_random_regions_50_epochs_harderentropy_generator.h5'\n",
    "model_save_dir = '/gpfs/commons/groups/knowles_lab/ting/DEN_splicing_pretrained_models/'\n",
    "\n",
    "full_path = model_save_dir + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 15:35:05.000530: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2024-03-10 15:35:05.017520: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz\n",
      "2024-03-10 15:35:05.019342: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557987c54380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-10 15:35:05.019371: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/genesis-0.1-py3.7.egg/genesis/generator/genesis_generator.py:26: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From /gpfs/commons/home/tchen/al_project/genesis/original_den_env/lib/python3.7/site-packages/genesis-0.1-py3.7.egg/genesis/generator/genesis_generator.py:28: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator_model = load_model(filepath=str(full_path), custom_objects={'K': K, 'st_sampled_softmax': st_sampled_softmax, 'st_hardmax_softmax': st_hardmax_softmax}, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence_class_seed (InputLayer (32, 1)              0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_rand_sequence_class (Lam (32, 1)              0           sequence_class_seed[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "noise_input_1 (InputLayer)      (32, 100)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise_input_2 (InputLayer)      (32, 100)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_rand_input_1 (Lambda)    (32, 100)            0           noise_input_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (32, 1)              0           lambda_rand_sequence_class[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_rand_input_2 (Lambda)    (32, 100)            0           noise_input_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (32, 101)            0           lambda_rand_input_1[0][0]        \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (32, 101)            0           lambda_rand_input_2[0][0]        \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy_dense_1 (Dense)          (32, 3456)           352512      concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (32, 9, 1, 384)      0           policy_dense_1[0][0]             \n",
      "                                                                 policy_dense_1[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "policy_deconv_0 (Conv2DTranspos (32, 23, 1, 256)     688384      reshape_1[0][0]                  \n",
      "                                                                 reshape_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "policy_batch_norm_0 (BatchNorma (32, 23, 1, 256)     1024        policy_deconv_0[0][0]            \n",
      "                                                                 policy_deconv_0[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (32, 23, 1, 256)     0           policy_batch_norm_0[0][0]        \n",
      "                                                                 policy_batch_norm_0[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "policy_deconv_1 (Conv2DTranspos (32, 52, 1, 192)     393408      lambda_2[0][0]                   \n",
      "                                                                 lambda_2[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy_batch_norm_1 (BatchNorma (32, 52, 1, 192)     768         policy_deconv_1[0][0]            \n",
      "                                                                 policy_deconv_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (32, 52, 1, 192)     0           policy_batch_norm_1[0][0]        \n",
      "                                                                 policy_batch_norm_1[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "policy_deconv_2 (Conv2DTranspos (32, 109, 1, 128)    172160      lambda_3[0][0]                   \n",
      "                                                                 lambda_3[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy_batch_norm_2 (BatchNorma (32, 109, 1, 128)    512         policy_deconv_2[0][0]            \n",
      "                                                                 policy_deconv_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (32, 109, 1, 128)    0           policy_batch_norm_2[0][0]        \n",
      "                                                                 policy_batch_norm_2[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "policy_conv_3 (Conv2D)          (32, 109, 1, 128)    131200      lambda_4[0][0]                   \n",
      "                                                                 lambda_4[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy_batch_norm_3 (BatchNorma (32, 109, 1, 128)    512         policy_conv_3[0][0]              \n",
      "                                                                 policy_conv_3[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (32, 109, 1, 128)    0           policy_batch_norm_3[0][0]        \n",
      "                                                                 policy_batch_norm_3[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "policy_conv_4 (Conv2D)          (32, 109, 1, 64)     65600       lambda_5[0][0]                   \n",
      "                                                                 lambda_5[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "policy_batch_norm_4 (BatchNorma (32, 109, 1, 64)     256         policy_conv_4[0][0]              \n",
      "                                                                 policy_conv_4[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (32, 109, 1, 64)     0           policy_batch_norm_4[0][0]        \n",
      "                                                                 policy_batch_norm_4[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "policy_conv_5 (Conv2D)          (32, 109, 1, 4)      2052        lambda_6[0][0]                   \n",
      "                                                                 lambda_6[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "template_dense (Embedding)      (32, 1, 436)         436         lambda_rand_sequence_class[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mask_dense (Embedding)          (32, 1, 436)         436         lambda_rand_sequence_class[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (32, 109, 4, 1)      0           policy_conv_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (32, 109, 4, 1)      0           template_dense[0][0]             \n",
      "                                                                 mask_dense[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (32, 109, 4, 1)      0           policy_conv_5[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking_layer (Lambda)          (32, 109, 4, 1)      0           reshape_2[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_4[1][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_4[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (320, 109, 4, 1)     0           masking_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (320, 109, 4, 1)     0           masking_layer[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pwm_sampler_1 (Lambda)          (320, 109, 4, 1)     0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pwm_sampler_2 (Lambda)          (320, 109, 4, 1)     0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (320, 109, 4, 1)     0           reshape_4[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pwm_1 (Softmax)                 (32, 109, 4, 1)      0           masking_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pwm_2 (Softmax)                 (32, 109, 4, 1)      0           masking_layer[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (32, 10, 109, 4, 1)  0           pwm_sampler_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (32, 10, 109, 4, 1)  0           pwm_sampler_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (32, 10, 109, 4, 1)  0           lambda_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,809,260\n",
      "Trainable params: 1,806,852\n",
      "Non-trainable params: 2,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (101, 3456)\n",
      "1 (3456,)\n",
      "2 (7, 1, 256, 384)\n",
      "3 (256,)\n",
      "4 (256,)\n",
      "5 (256,)\n",
      "6 (256,)\n",
      "7 (256,)\n",
      "8 (8, 1, 192, 256)\n",
      "9 (192,)\n",
      "10 (192,)\n",
      "11 (192,)\n",
      "12 (192,)\n",
      "13 (192,)\n",
      "14 (7, 1, 128, 192)\n",
      "15 (128,)\n",
      "16 (128,)\n",
      "17 (128,)\n",
      "18 (128,)\n",
      "19 (128,)\n",
      "20 (8, 1, 128, 128)\n",
      "21 (128,)\n",
      "22 (128,)\n",
      "23 (128,)\n",
      "24 (128,)\n",
      "25 (128,)\n",
      "26 (8, 1, 128, 64)\n",
      "27 (64,)\n",
      "28 (64,)\n",
      "29 (64,)\n",
      "30 (64,)\n",
      "31 (64,)\n",
      "32 (8, 1, 64, 4)\n",
      "33 (4,)\n",
      "34 (1, 436)\n",
      "35 (1, 436)\n"
     ]
    }
   ],
   "source": [
    "for i, weight in enumerate(generator_model.get_weights()):\n",
    "    print(i, weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get order of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generator_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got the weights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the weights into a numpy object file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/gpfs/commons/groups/knowles_lab/ting/DEN_splicing_generator_weights/'\n",
    "save_name = 'target_isoform_00.npy'\n",
    "\n",
    "np.save(save_path+save_name, np.array(generator_model.get_weights(), dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're gonna try loading in the weights into our PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/commons/home/tchen/al_project/active-learning-cnns-gps/project-env/lib64/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# point path to our repo\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    '/gpfs/commons/home/tchen/al_project/active-learning-cnns-gps/src'\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from models.den import Generator\n",
    "import torch\n",
    "from data.old_dataset import create_sequence_templates\n",
    "from torch import nn\n",
    "from models.base_cnn import OracleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/gpfs/commons/groups/knowles_lab/ting/DEN_splicing_generator_weights/'\n",
    "save_name = 'target_isoform_00.npy'\n",
    "\n",
    "target_isoform_net_weights = np.load(save_path+save_name, allow_pickle=True)\n",
    "\n",
    "# list of numpy arrays\n",
    "weights = target_isoform_net_weights.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# embedding_template, embedding_mask = create_sequence_templates()\n",
    "\n",
    "# need to extract embedding template and mask from pretrained network\n",
    "pretrained_embedding_template = torch.tensor(weights[-2]).to(device)\n",
    "pretrained_embedding_mask = torch.tensor(weights[-1]).to(device)\n",
    "\n",
    "n_samples = 10\n",
    "n_classes = 1\n",
    "seq_length = 109\n",
    "latent_dim = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_generator = Generator(embedding_template=pretrained_embedding_template,\n",
    "                                   embedding_mask=pretrained_embedding_mask,\n",
    "                                   device=device,\n",
    "                                   latent_dim=latent_dim,\n",
    "                                   batch_size=batch_size,\n",
    "                                   seq_length=seq_length,\n",
    "                                   n_classes=n_classes,\n",
    "                                   n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=101, out_features=3456, bias=True)\n",
       "  (1): ConvTranspose2d(384, 256, kernel_size=(7, 1), stride=(2, 1))\n",
       "  (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): ConvTranspose2d(256, 192, kernel_size=(8, 1), stride=(2, 1))\n",
       "  (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ConvTranspose2d(192, 128, kernel_size=(7, 1), stride=(2, 1))\n",
       "  (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Conv2d(128, 64, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Conv2d(64, 4, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_generator.generator_network.generator_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_keras_weight_idx = 0\n",
    "\n",
    "for i, layer in enumerate(torch_generator.generator_network.generator_network):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        # transfer linear layer weights and biases\n",
    "        assert tuple(layer.weight.data.shape) == weights[running_keras_weight_idx].T.shape\n",
    "        layer.weight.data = torch.from_numpy(weights[running_keras_weight_idx].T)\n",
    "        running_keras_weight_idx += 1\n",
    "\n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.ConvTranspose2d):\n",
    "        # transfer convtranspose2d weights and biases\n",
    "        assert tuple(layer.weight.data.shape) == np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]).shape\n",
    "        layer.weight.data = torch.from_numpy(np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]))\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.Conv2d):\n",
    "        # transfer conv2d weights and biases\n",
    "        assert tuple(layer.weight.data.shape) == np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]).shape\n",
    "        layer.weight.data = torch.from_numpy(np.transpose(weights[running_keras_weight_idx], axes=[3, 2, 0, 1]))\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "    elif isinstance(layer, nn.BatchNorm2d):\n",
    "        # transfer batch norm gamma, beta, running mean, running variance\n",
    "        # order from keras model should be gamma, beta, moving mean, moving variance\n",
    "        assert tuple(layer.weight.data.shape) == weights[running_keras_weight_idx].shape # this might need a transpose\n",
    "        layer.weight.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.bias.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.bias.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.running_mean.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.running_mean.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1\n",
    "        \n",
    "        assert layer.running_var.data.shape == weights[running_keras_weight_idx].shape\n",
    "        layer.running_var.data = torch.from_numpy(weights[running_keras_weight_idx])\n",
    "        running_keras_weight_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded the model, let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (generator_network): GeneratorNetwork(\n",
       "    (generator_network): ModuleList(\n",
       "      (0): Linear(in_features=101, out_features=3456, bias=True)\n",
       "      (1): ConvTranspose2d(384, 256, kernel_size=(7, 1), stride=(2, 1), padding=('v', 'a', 'l', 'i', 'd'))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (3): ConvTranspose2d(256, 192, kernel_size=(8, 1), stride=(2, 1), padding=('v', 'a', 'l', 'i', 'd'))\n",
       "      (4): BatchNorm2d(192, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (5): ConvTranspose2d(192, 128, kernel_size=(7, 1), stride=(2, 1), padding=('v', 'a', 'l', 'i', 'd'))\n",
       "      (6): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (9): Conv2d(128, 64, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "      (10): BatchNorm2d(64, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (11): Conv2d(64, 4, kernel_size=(8, 1), stride=(1, 1), padding=same)\n",
       "    )\n",
       "  )\n",
       "  (onehot_template_layer): Embedding(1, 436)\n",
       "  (onehot_mask_layer): Embedding(1, 436)\n",
       "  (straight_through): StraightThroughEstimator()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_generator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv_transpose2d(): argument 'padding' (position 5) must be tuple of ints, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-27ceb6d97f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/al_project/active-learning-cnns-gps/project-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/al_project/active-learning-cnns-gps/src/models/den.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, random_seed)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mseed_input_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatent_input_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mraw_logits_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_input_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mraw_logits_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_input_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/al_project/active-learning-cnns-gps/project-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/al_project/active-learning-cnns-gps/src/models/den.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# reshape for 2D ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/al_project/active-learning-cnns-gps/project-env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/al_project/active-learning-cnns-gps/project-env/lib64/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    923\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    924\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv_transpose2d(): argument 'padding' (position 5) must be tuple of ints, not tuple"
     ]
    }
   ],
   "source": [
    "torch_generator.eval()\n",
    "samples = None\n",
    "with torch.no_grad():\n",
    "    samples = torch_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0][0][0].reshape((109, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save generated samples\n",
    "save_path = '/gpfs/commons/groups/knowles_lab/ting/'\n",
    "save_name = 'pytorch_generated_sequences_target_isoform_00.npy'\n",
    "\n",
    "np.save(save_path+save_name, samples[0].detach().cpu().numpy(), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save pwm\n",
    "save_path = '/gpfs/commons/groups/knowles_lab/ting/'\n",
    "save_name = 'pytorch_optimized_pwm_target_isoform_00.npy'\n",
    "\n",
    "np.save(save_path+save_name, samples[2].detach().cpu().numpy(), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check length of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DIRECTORY = '/gpfs/commons/home/tchen/al_project/active-learning-cnns-gps'\n",
    "dataset_path = PATH_TO_DIRECTORY + '/old_data/5SS_compressed.txt'\n",
    "seq_len = 101\n",
    "n = 265137\n",
    "inputs = np.zeros((n, seq_len, 4))\n",
    "prob_s1 = np.zeros(n)\n",
    "\n",
    "with open(dataset_path) as f:\n",
    "    ind = 0\n",
    "    for line in f:\n",
    "        mod_line = line.split('\\t')\n",
    "        print(mod_line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
